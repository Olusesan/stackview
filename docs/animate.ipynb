{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d4e8e21-d4df-431e-ac0b-1e2f4442d5f1",
   "metadata": {},
   "source": [
    "# Animate\n",
    "Using `stackview.animate` you can visualize timelapse data in Jupyter notebooks. The videos are stored to disk in .gif format. This allows rendering them in github repositories. However, make sure that the files are not too big and consider sub-sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a92b038-5c7e-4ec5-8ec5-47d7519f3cd3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.7.8'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import stackview\n",
    "stackview.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94b83785-ba10-48dd-a101-8a172463cd49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from skimage.io import imread\n",
    "from skimage.filters import gaussian\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0292b39b-3691-4ff2-b77f-39c8eee871bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(254, 256)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blobs = imread(\"data/blobs.tif\")\n",
    "blobs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22440d2b-a082-448f-9c3f-716be6f03564",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 254, 256)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blobs_images = np.asarray([gaussian(blobs, sigma=s, preserve_range=True) for s in list(range(0, 15)) + list(range(15, 0, -1))])\n",
    "blobs_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6aa2f1de-4ab1-4019-b116-3c5258c5a6d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "![](images/timelapse.gif)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stackview.animate(blobs_images, filename=\"images/timelapse.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a3cc53c-3409-4fdf-8b89-d2cf4640e457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "![](images/timelapse2.gif)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stackview.animate(blobs_images, filename=\"images/timelapse2.gif\", frame_delay_ms=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fa6e6fd-c765-4dea-bddc-51402e9d73a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "![](images/timelapse3.gif)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stackview.animate_curtain(blobs, blobs > 128, filename=\"images/timelapse3.gif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02586e3d-d704-4133-b398-f2109dc886ca",
   "metadata": {
    "tags": []
   },
   "source": [
    "## RGB image support\n",
    "We can also do this using RGB images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ba737c7-8530-43c4-b07f-c3468f8a8aea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 336, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hela = imread(\"data/hela-cells.tif\")[::2, ::2]\n",
    "hela.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc04d16d-ab33-4047-a1a0-4240d8a406ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hela = hela / hela.max() * 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4615a840-17f4-4514-a0a6-ace39c749f49",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 256, 336, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hela_images = np.asarray([gaussian(hela, sigma=s, preserve_range=True, channel_axis=2) for s in list(range(0, 15)) + list(range(15, 0, -1))])\n",
    "hela_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93144d76-70e7-4acc-9a24-96e4f04b93c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "![](images/timelapse4.gif)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stackview.animate(hela_images, filename=\"images/timelapse4.gif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69f245c-0ac9-461f-862f-5d39a8129520",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Trouble shooting: image type conversion\n",
    "In case the input image is not 8-bit integers or with pixel intensities in small or large ranges, consider normalizing the images.\n",
    "\n",
    "### Example 1: Black image output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62393952-e396-4078-a735-efda5b5a69db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\structure\\code\\stackview\\stackview\\_animate.py:39: UserWarning: The timelapse has a small intensity range between 0 and 1. Consider normalizing it to the range between 0 and 255.\n",
      "  warnings.warn(\"The timelapse has a small intensity range between 0 and 1. Consider normalizing it to the range between 0 and 255.\")\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "![](images/timelapse5.gif)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blobs_images2 = np.asarray([gaussian(blobs, sigma=s) for s in range(0, 10, 5)])\n",
    "\n",
    "stackview.animate(blobs_images2, frame_delay_ms=1000, filename=\"images/timelapse5.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0d62266-02a7-4af6-8a8c-dcd8373325fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.03137254901960784, 0.9725490196078431)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blobs_images2.min(), blobs_images2.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4863447c-4773-4fea-8f56-d5adc991ade3",
   "metadata": {
    "tags": []
   },
   "source": [
    "The images in this timelapse have intensity between 0 and 1. By normalizing it to the range 0-255, we can see the content in the animation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1351f735-4693-4f0c-88eb-58aa8c9e1109",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "![](images/timelapse6.gif)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blobs_images2_ = blobs_images2 / blobs_images2.max() * 255\n",
    "\n",
    "stackview.animate(blobs_images2_, frame_delay_ms=1000, filename=\"images/timelapse6.gif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a40fb27-689a-4131-b1d2-125260d76910",
   "metadata": {},
   "source": [
    "### Example 2: Overflowing intensities\n",
    "If the intensity in the image exceeds the range 0-255, images may show borders where the intensity is overflowing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2cf785ba-db84-49c5-ad41-a7866167c295",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\structure\\code\\stackview\\stackview\\_animate.py:41: UserWarning: The timelapse has an intensity range exceeding 0..255. Consider normalizing it to the range between 0 and 255.\n",
      "  warnings.warn(\"The timelapse has an intensity range exceeding 0..255. Consider normalizing it to the range between 0 and 255.\")\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "![](images/timelapse7.gif)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hela_image2 = imread(\"data/hela-cells.tif\")[::2, ::2]\n",
    "\n",
    "hela_images2 = np.asarray([gaussian(hela_image2, sigma=s, preserve_range=True, channel_axis=2) for s in range(0, 10, 5)])\n",
    "\n",
    "stackview.animate(hela_images2, frame_delay_ms=1000, filename=\"images/timelapse7.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81594677-fc41-45d7-9f26-8f8c3e5f4bbd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 4095.0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hela_images2.min(), hela_images2.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4e5819-044a-4ab4-8a2d-255f9650ba9e",
   "metadata": {},
   "source": [
    "Also in this case, normalizing the image intensity to the range 0-255 helps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26fe630e-2972-4da1-a40f-bd16e0236621",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "![](images/timelapse8.gif)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hela_images2_ = hela_images2 / hela_images2.max() * 255\n",
    "\n",
    "stackview.animate(hela_images2_, frame_delay_ms=1000, filename=\"images/timelapse8.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e1eecc-a24b-4574-adb5-35c1414a5943",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
